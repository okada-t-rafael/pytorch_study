{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPW8Jh+E46egr6+EQrdMEsX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okada-t-rafael/pytorch_study/blob/master/05_pytorch_going_modular_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises"
      ],
      "metadata": {
        "id": "Wyg_UjcVcqGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"going_modular\", exist_ok=True)"
      ],
      "metadata": {
        "id": "cvyJDMuqd_yw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1\n",
        "Turn the code to get the data (from section 1. Get Data) into a Python script, such as `get_data.py`.\n",
        "\n",
        "* When you run the script using `python get_data.py` it should check if the data already exists and skip downloading if it does.\n",
        "\n",
        "* If the data download is successful, you should be able to access the `pizza_steak_sushi` images from the `data` directory."
      ],
      "metadata": {
        "id": "HfXrK97ac2Tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/get_data.py\n",
        "\"\"\"\n",
        "Contains functions for downloading an image dataset and unzip it.\n",
        "\"\"\"\n",
        "import logging\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def download_zip_dataset(\n",
        "        dataset_url: str,\n",
        "        folder_name: str,\n",
        "        ) -> Tuple[Path, bool]:\n",
        "    \"\"\"Downloads an image dataset from a given url and unzip it.\n",
        "\n",
        "    The files within the zip must respect the following structure:\n",
        "    .\n",
        "    |-- root_folder\n",
        "        |-- test\n",
        "        |   |-- class_one\n",
        "        |   |-- class_two\n",
        "        `-- train\n",
        "            |-- class_one\n",
        "            |-- class_two\n",
        "\n",
        "    Args:\n",
        "        dataset_url: An URL of a zip file containing images for each class\n",
        "            divided into train and test subfolders.\n",
        "        folder_name: The name of the folder to be creatd when unzipping the\n",
        "            zip files.\n",
        "\n",
        "    Returns:\n",
        "        The path where the image were download and a boolean indicating whether\n",
        "        everything was executed as expected. For example:\n",
        "\n",
        "        (PosixPath(\"folder_name\"), True)\n",
        "\n",
        "        If last value within the return is a False, should not use the other\n",
        "        values.\n",
        "    \"\"\"\n",
        "    # Setup path to a data folder\n",
        "    data_path: Path = Path(\"data\")\n",
        "    image_path: Path = data_path / folder_name\n",
        "\n",
        "    # Check whether the image folder already exists, if now download it...\n",
        "    if image_path.is_dir():\n",
        "        logging.info(\n",
        "            f\"Directory '{image_path}' already exists. Skipping download.\")\n",
        "        return image_path, True\n",
        "\n",
        "    logging.info(f\"Creating directory: '{image_path}'\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download zipfile\n",
        "    zipfile_name = dataset_url.split(\"/\")[-1]\n",
        "    try:\n",
        "        logging.info(f\"Downloading: '{zipfile_name}'\")\n",
        "        req = requests.get(dataset_url)\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logging.error(f\"Error while downloading '{dataset_url}': {e}\")\n",
        "        return Path(\"\"), False\n",
        "\n",
        "    # Saving downloaded file\n",
        "    try:\n",
        "        with open(data_path / zipfile_name, \"wb\") as f:\n",
        "            f.write(req.content)\n",
        "    except IOError as e:\n",
        "        logging.error(f\"Error while writing '{zipfile_name}': {e}\")\n",
        "        return Path(\"\"), False\n",
        "\n",
        "    # Unzip images\n",
        "    try:\n",
        "        with zipfile.ZipFile(data_path / zipfile_name, \"r\") as zip_ref:\n",
        "            logging.info(f\"Unzipping: '{zipfile_name}'\")\n",
        "            zip_ref.extractall(image_path)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error while unzipping '{zipfile_name}': {e}\")\n",
        "        return Path(\"\"), False\n",
        "\n",
        "    return image_path, True\n"
      ],
      "metadata": {
        "id": "0LjyfmWwdUno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954282da-b545-4de0-88a3-81d05251076d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/get_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from going_modular.get_data import download_zip_dataset\n",
        "\n",
        "\n",
        "# Setting logging level.\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "\n",
        "# Some definitions\n",
        "DATASET_URL = \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\"\n",
        "WORK_FOLDER = \"pizza_steak_sushi\"\n",
        "\n",
        "# Donwload and unzip images.\n",
        "image_path, _ = download_zip_dataset(DATASET_URL, WORK_FOLDER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vUmcrjOjBMQ",
        "outputId": "380e3f94-60ff-4fb2-b556-6a263e8089cb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Creating directory: 'data/pizza_steak_sushi'\n",
            "INFO:root:Downloading: 'pizza_steak_sushi_20_percent.zip'\n",
            "INFO:root:Unzipping: 'pizza_steak_sushi_20_percent.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2\n",
        "Use Python's `argparse` modeule to be able to send the train.py custom hyperparameter values for training procedures.\n",
        "\n",
        "* Add an argument flag for using a different:\n",
        "    * Training/testing directory\n",
        "    * Learning rate\n",
        "    * Batch size\n",
        "    * Number of epochs to train for\n",
        "    * Number of hidden units in the TinyVGG model\n",
        "        * Keep the default values for each of the above arguments as what they already are (as in notebook 05)\n",
        "* For example, you should be able to run something similar to the following line to train a TinyVGG model with a learning rate of 0.003 and batch size of 64 for 20 epochs: `python train.py --learning_rate 0.003 --batch_size 64 --num_epochs 20`.\n",
        "* **Note:** Since `train.py` leverages the other scripts we created in section 05, such as, `model_builder.py`, `utils.py` and `engine.py`, you'll have to make sure they're available to use too. You can find these in the going_modular forder of the course GitHub."
      ],
      "metadata": {
        "id": "twtPyM2plUGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/data_setup.py\n",
        "\"\"\"\n",
        "Contains functionality for creating PyTorch DataLoader for image classification\n",
        "data.\n",
        "\"\"\"\n",
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "# Default number of workers for DataLoader\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "\n",
        "class ErrorDataset(Dataset):\n",
        "    \"\"\"Dummy Dataset for creating a ZeroValue instance for DataLoaders.\"\"\"\n",
        "    def __len__(self):\n",
        "        return 0\n",
        "\n",
        "\n",
        "def create_dataloaders(\n",
        "        image_path: Path,\n",
        "        train_transform: transforms.Compose,\n",
        "        test_transform: transforms.Compose,\n",
        "        batch_size: int=32,\n",
        "        num_workers: int=NUM_WORKERS\n",
        "        ) -> Tuple[Tuple[DataLoader, DataLoader], List[str], bool]:\n",
        "    \"\"\"Creates training and testing DataLoaders.\n",
        "\n",
        "    Takes in a image path directory and turns them into PyTorch Datasets and\n",
        "    then into PyTorch DataLoaders.\n",
        "\n",
        "    Args:\n",
        "        image_path: Location where the train and test forlder are located.\n",
        "        train_transform: Transformations to be applied to the train images.\n",
        "        test_transform: Transformations to be applied to the test images.\n",
        "        batch_size: Size of the batches to be created for the dataloaders.\n",
        "\n",
        "    Returns:\n",
        "        A tuple of dataloaders for the train and test datasets, a list\n",
        "        containing the names of the images labels, and a bool indicating\n",
        "        whether the function was executed as expected.\n",
        "\n",
        "        If last value within the return is a False, should not use the other\n",
        "        values.\n",
        "    \"\"\"\n",
        "    # Create datasets\n",
        "    logging.info(\"Creating Datasets.\")\n",
        "\n",
        "    if not image_path.is_dir():\n",
        "        logging.error(f\"There is no folder: '{image_path}'.\")\n",
        "        err_dataloader = DataLoader(ErrorDataset())\n",
        "        return ((err_dataloader, err_dataloader), [], False)\n",
        "\n",
        "    try:\n",
        "        train_dataset = datasets.ImageFolder(\n",
        "            root=image_path / \"train\",\n",
        "            transform=train_transform)\n",
        "        test_dataset = datasets.ImageFolder(\n",
        "            root=image_path / \"test\",\n",
        "            transform=test_transform)\n",
        "        image_classes_list = train_dataset.classes\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading images from: '{image_path}'.\")\n",
        "        err_dataloader = DataLoader(ErrorDataset())\n",
        "        return ((err_dataloader, err_dataloader), [], False)\n",
        "\n",
        "    # Turn datasets into dataloaders\n",
        "    logging.info(\"Turning train and test datasets into dataloaders.\")\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=True,\n",
        "        pin_memory=True)\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        dataset=test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=False,\n",
        "        pin_memory=True)\n",
        "\n",
        "    return ((train_dataloader, test_dataloader), image_classes_list, True)\n"
      ],
      "metadata": {
        "id": "pZ3SGB_FT3R-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b4cd0f-baa9-4b6f-a6ca-850a5700b60a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/engine.py\n",
        "\"\"\"\n",
        "Contains functions for training and testing a PyTorch model.\n",
        "\"\"\"\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "\n",
        "def train_step(\n",
        "        model: torch.nn.Module,\n",
        "        dataloader: torch.utils.data.DataLoader,\n",
        "        loss_fn: torch.nn.Module,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        device: str\n",
        "        ) -> Tuple[float, float]:\n",
        "    \"\"\"Trains a PyTorch model for a single epoch.\n",
        "\n",
        "    Turns a target PyTorch model to training mode and then runs through all the\n",
        "    required training steps (forward pass, loss calculation, optimizer step).\n",
        "\n",
        "    Args:\n",
        "        model: A Pytorch model to be trained.\n",
        "        dataloader: A Dataloader instance for the model to be trained on.\n",
        "        loss_fn: A PyTorch loss function to minimize.\n",
        "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "        A tuple of training loss and training accuracy metrics. In the form\n",
        "        (train_loss, train_accuracy). For example: (0.1112, 0.8743)\n",
        "    \"\"\"\n",
        "    # Put the model into target device\n",
        "    model.to(device)\n",
        "\n",
        "    # Pu the model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # Setup train loss and train accuracy variables\n",
        "    train_loss: float = 0.0\n",
        "    train_acc: float = 0.0\n",
        "\n",
        "    # Loop through dataloader data batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Send data to the target device\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred_logits = model(X)  # output model logits\n",
        "\n",
        "        # 2. Calculate the loss\n",
        "        loss = loss_fn(y_pred_logits, y)\n",
        "        train_loss += loss.item()  # convert this tensor to a standard python number\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy metric\n",
        "        y_pred_probs = torch.softmax(y_pred_logits, dim=1)\n",
        "        y_pred_labels = torch.argmax(y_pred_probs, dim=1)\n",
        "        train_acc += (y_pred_labels == y).sum().item() / len(y_pred_labels)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "def test_step(\n",
        "        model: torch.nn.Module,\n",
        "        dataloader: torch.utils.data.DataLoader,\n",
        "        loss_fn: torch.nn.Module,\n",
        "        device: str) -> Tuple[float, float]:\n",
        "    \"\"\"Tests a PyTorch model for a single epoch.\n",
        "\n",
        "    Turns a target PyTorch model to 'eval' mode and then performs a forward\n",
        "    pass on a testing dataset.\n",
        "\n",
        "    Args:\n",
        "        model: A Pytorch model to be tested.\n",
        "        dataloader: A Dataloader instance for the model to be tested on.\n",
        "        loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
        "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "        A tuple of testing loss and testing accuracy metrics. In the form\n",
        "        (test_loss, test_accuracy). For example: (0.1112, 0.8743)\n",
        "    \"\"\"\n",
        "    # Put model into target device\n",
        "    model.to(device)\n",
        "\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Step test loss and test accuracy variables\n",
        "    test_loss: float = 0.0\n",
        "    test_acc: float = 0.0\n",
        "\n",
        "    # Turn on inference mode\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to target device\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate the loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Calculate the accuracy\n",
        "            test_pred_probs = test_pred_logits.softmax(dim=1)\n",
        "            test_pred_labels = test_pred_probs.argmax(dim=1)\n",
        "            test_acc += (test_pred_labels == y).sum().item() / len(test_pred_labels)\n",
        "\n",
        "        # Adjust metrics to get average loss and accuracy per batch\n",
        "        test_loss = test_loss / len(dataloader)\n",
        "        test_acc = test_acc / len(dataloader)\n",
        "\n",
        "        return test_loss, test_acc\n",
        "\n",
        "\n",
        "def train(\n",
        "        model: torch.nn.Module,\n",
        "        train_dataloader: torch.utils.data.DataLoader,\n",
        "        test_dataloader: torch.utils.data.DataLoader,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        loss_fn: torch.nn.Module,\n",
        "        epochs: int,\n",
        "        device: str,\n",
        "        ) -> Dict[str, List[float]]:\n",
        "    \"\"\"\n",
        "    Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target model through 'train_step' and 'test_step' functions for a\n",
        "    number of epochs, training and testing the model in the same epoch loop.\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Args:\n",
        "        model: A PyTorch model to be trained and tested.\n",
        "        train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "        test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "        loss_fn: A PyTorch loss function to calculate on both datasets.\n",
        "        epochs: An integer indicating how many epochs to train for.\n",
        "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "        A dictionary of training and testing loss as well as training and\n",
        "        testing accuracy metrics. Each metric has a value in a list for each\n",
        "        epoch.\n",
        "\n",
        "        For example if training for epochs = 2: {\n",
        "            train_loss: [2.0616, 1.0537],\n",
        "            train_acc: [0.3945, 0.3945],\n",
        "            test_loss: [1.2641, 1.5706],\n",
        "            test_acc: [0.3400, 0.2973]\n",
        "        }\n",
        "    \"\"\"\n",
        "    # Create an empty results dictionary\n",
        "    results: Dict[str, List[float]] = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": []}\n",
        "\n",
        "    # Loop through training and testing steps for a number o epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Training step\n",
        "        train_loss, train_acc = train_step(\n",
        "            model=model,\n",
        "            dataloader=train_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            optimizer=optimizer,\n",
        "            device=device)\n",
        "\n",
        "        # Test step\n",
        "        test_loss, test_acc = test_step(\n",
        "            model=model,\n",
        "            dataloader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "            f\" - Epoch: {epoch} | \"\n",
        "            f\"Train_loss: {train_loss:.4f}, Train_acc: {train_acc:.3f}% | \"\n",
        "            f\"Test_loss: {test_loss:.4f}, Test_acc: {test_acc:.3f}%\")\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "O1IVVNLrnaPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c3e46c-7780-4bab-f0bf-c497b2f50a64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/model_builder.py\n",
        "\"\"\"\n",
        "Contains PyTorch model code to instantiate a TinyVGG model.\n",
        "\"\"\"\n",
        "import torch\n",
        "from torch import nn\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "    \"\"\"Creates the TinyVGG architecture.\n",
        "\n",
        "    Replicates the TinyVGG architecture from the CNN exaplainer website in\n",
        "    Pytorch. See more: https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int,\n",
        "            hidden_units: int,\n",
        "            out_features: int,\n",
        "            img_shape: Tuple[int, int]\n",
        "            ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # First block\n",
        "        self.conv_block_1, adj_img_shape = TinyVGG._create_conv_block(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=hidden_units,\n",
        "            img_shape=img_shape)\n",
        "\n",
        "        # Second block\n",
        "        self.conv_block_2, adj_img_shape = TinyVGG._create_conv_block(\n",
        "            in_channels=hidden_units,\n",
        "            out_channels=hidden_units,\n",
        "            img_shape=adj_img_shape)\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = TinyVGG._create_classifier_block(\n",
        "            in_features=hidden_units * adj_img_shape[0] * adj_img_shape[1],\n",
        "            out_features=out_features)\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))\n",
        "\n",
        "\n",
        "    def _create_conv_block(\n",
        "            in_channels: int,\n",
        "            out_channels: int,\n",
        "            img_shape: Tuple[int, int]\n",
        "            ) -> Tuple[nn.Sequential, Tuple[int, int]]:\n",
        "        \"\"\"Creates a block of the neural network.\n",
        "\n",
        "        This block includes two Conv2d and one MaxPool2d. And it also\n",
        "        calculates the adjusted size of the 'image' for the flatten layer.\n",
        "\n",
        "        Args:\n",
        "            in_channels: The input size channel of the first conv layer.\n",
        "            out_channels: The output size channel of the second conv layer.\n",
        "            img_shape: The shape of the 'image' after passing through this\n",
        "                block. It is influenced by the Conv2d layers and the MaxPool2d\n",
        "                layer (see documentatin to adjust accordinly).\n",
        "\n",
        "        Return:\n",
        "            The instance of the block and the adjusted size of the 'image'.\n",
        "        \"\"\"\n",
        "        # Create the conv block\n",
        "        conv_block = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=out_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(\n",
        "                kernel_size=2,\n",
        "                stride=2))\n",
        "\n",
        "        # Calculate the ajusted image shape\n",
        "        img_x, img_y = img_shape\n",
        "        img_x -= 2  # first Conv2d\n",
        "        img_x -= 2  # second Conv2d\n",
        "        img_x = int(img_x / 2)  # MaPool2d\n",
        "        img_y -= 2  # first Conv2d\n",
        "        img_y -= 2  # second Conv2d\n",
        "        img_y = int(img_y / 2)  # MaPool2d\n",
        "\n",
        "        return conv_block, (img_x, img_y)\n",
        "\n",
        "\n",
        "    def _create_classifier_block(\n",
        "            in_features: int,\n",
        "            out_features: int,\n",
        "            ) -> nn.Sequential:\n",
        "        \"\"\"Creates a classifier block to the neural network.\n",
        "\n",
        "        It is composed by a flatten layer and a linear layer.\n",
        "\n",
        "        Args:\n",
        "            in_features: The number of features to be inserted in the linear\n",
        "                layer. Note that this number must be ajusted to due to the\n",
        "                flatten layer.\n",
        "            out_feataures: Number of labels for the neural network to predict.\n",
        "\n",
        "        Return:\n",
        "            An instance of the block.\n",
        "        \"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(\n",
        "                in_features=in_features,\n",
        "                out_features=out_features\n",
        "            )\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdJbkLyntguQ",
        "outputId": "93d01b09-06d2-436f-8b43-5ae071e839b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/utils.py\n",
        "\"\"\"\n",
        "Contains various utility functions for PyTorch model training and saving.\n",
        "\"\"\"\n",
        "import logging\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def save_model(\n",
        "        model: torch.nn.Module,\n",
        "        target_dir: str,\n",
        "        model_name: str,\n",
        "        ) -> bool:\n",
        "    \"\"\"Saves a PyTorch model to a target directory.\n",
        "\n",
        "    Args:\n",
        "        model: A target PyTorch model to save.\n",
        "        target_dir: A directory for saving the model to.\n",
        "        model_name: A filename for the saved model. Should include either\n",
        "            \".pth\" or \".pt\" as the filename extension.\n",
        "\n",
        "    Returns:\n",
        "        A boolean indicating whether the save operation was executed without\n",
        "        errors.\n",
        "    \"\"\"\n",
        "    # Create target directory\n",
        "    target_dir_path = Path(target_dir)\n",
        "    target_dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Create model save path\n",
        "    if not model_name.endswith((\".pth\", \".pt\")):\n",
        "        logging.error(\"Model's name should end with '.pt' or '.pth'.\")\n",
        "        return False\n",
        "    model_save_path = target_dir_path / model_name\n",
        "\n",
        "    # Save the model state_dict()\n",
        "    try:\n",
        "        torch.save(obj=model.state_dict(), f=model_save_path)\n",
        "    except Exception as e:\n",
        "        logging.erro(f\"Error while saving model: {e}\")\n",
        "        return False\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx3MkaSav-uI",
        "outputId": "8ce98f06-d5f7-4bf8-8849-1d16d34ef52e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/train.py\n",
        "\"\"\"\n",
        "Trains a PyTorch image classification model using device-agnostic code.\n",
        "\"\"\"\n",
        "import argparse\n",
        "import data_setup\n",
        "import engine\n",
        "import get_data\n",
        "import logging\n",
        "import model_builder\n",
        "import os\n",
        "import torch\n",
        "import utils\n",
        "from pathlib import Path\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "# Create a parser\n",
        "parser = argparse.ArgumentParser(description=\"Get some hyperparameters.\")\n",
        "\n",
        "# Add an arg for num_epochs\n",
        "parser.add_argument(\n",
        "    \"--num_epochs\",\n",
        "    default=10,\n",
        "    type=int,\n",
        "    help=\"the number of epochs to train for\")\n",
        "\n",
        "# Add an arg for batch_size\n",
        "parser.add_argument(\n",
        "    \"--batch_size\",\n",
        "    default=32,\n",
        "    type=int,\n",
        "    help=\"numer of samples per batch\")\n",
        "\n",
        "# Add an arg for hidden_units\n",
        "parser.add_argument(\n",
        "    \"--hidden_units\",\n",
        "    default=10,\n",
        "    type=int,\n",
        "    help=\"number of hidden units in hidden layers\")\n",
        "\n",
        "# Add an arg for learning_rate\n",
        "parser.add_argument(\n",
        "    \"--learning_rate\",\n",
        "    default=0.001,\n",
        "    type=float,\n",
        "    help=\"learning rate to use for model\")\n",
        "\n",
        "# Add an arg for the image path\n",
        "parser.add_argument(\n",
        "    \"--image_path\",\n",
        "    default=\"data/pizza_steak_sushi\",\n",
        "    type=str,\n",
        "    help=\"image path in standard image classification format\"\n",
        ")\n",
        "\n",
        "# Get our arguments from the parser\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Setup hyperparameters\n",
        "NUM_EPOCHS = args.num_epochs\n",
        "BATCH_SIZE = args.batch_size\n",
        "HIDDEN_UNITS = args.hidden_units\n",
        "LEARNING_RATE = args.learning_rate\n",
        "IMAGE_PATH = Path(args.image_path)\n",
        "\n",
        "logging.info(\n",
        "    f\"Training a model epochs: {NUM_EPOCHS} \\| \"\n",
        "    f\"batch size: {BATCH_SIZE} \\| hidden units: {HIDDEN_UNITS} \\| \"\n",
        "    f\"learning rate: {LEARNING_RATE}\")\n",
        "\n",
        "# Setup target device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Create transforms\n",
        "train_data_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64), antialias=True),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "test_data_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64), antialias=True),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "# Create DataLoaders\n",
        "dataloaders, class_name_list, ok = data_setup.create_dataloaders(\n",
        "    image_path=IMAGE_PATH,\n",
        "    train_transform=train_data_transform,\n",
        "    test_transform=test_data_transform,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "# Create model\n",
        "model = model_builder.TinyVGG(\n",
        "    in_channels=3,\n",
        "    hidden_units=HIDDEN_UNITS,\n",
        "    out_features=len(class_name_list),\n",
        "    img_shape=(64, 64))\n",
        "\n",
        "# Set Loss and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    params=model.parameters(),\n",
        "    lr=LEARNING_RATE)\n",
        "\n",
        "# Training\n",
        "engine.train(\n",
        "    model=model,\n",
        "    train_dataloader=dataloaders[0],\n",
        "    test_dataloader=dataloaders[1],\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    device=device)\n",
        "\n",
        "# Save\n",
        "utils.save_model(\n",
        "    model=model,\n",
        "    target_dir=\"models\",\n",
        "    model_name=\"tinyvgg_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS88K8VXyOWx",
        "outputId": "945ca55c-cf10-4007-fff4-27b432e22bd9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python going_modular/train.py --num_epochs 50 --batch_size 32 --hidden_units 20 --learning_rate 0.00025"
      ],
      "metadata": {
        "id": "AwViCsvrzC7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4844d6e5-2607-40e3-e8ca-a2f0486fee9d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0% 0/50 [00:00<?, ?it/s] - Epoch: 0 | Train_loss: 1.0971, Train_acc: 0.296% | Test_loss: 1.0980, Test_acc: 0.287%\n",
            "  2% 1/50 [00:06<05:28,  6.71s/it] - Epoch: 1 | Train_loss: 1.0913, Train_acc: 0.317% | Test_loss: 1.0954, Test_acc: 0.281%\n",
            "  4% 2/50 [00:10<04:13,  5.27s/it] - Epoch: 2 | Train_loss: 1.0929, Train_acc: 0.329% | Test_loss: 1.0845, Test_acc: 0.338%\n",
            "  6% 3/50 [00:15<03:47,  4.83s/it] - Epoch: 3 | Train_loss: 1.0803, Train_acc: 0.431% | Test_loss: 1.0640, Test_acc: 0.500%\n",
            "  8% 4/50 [00:20<03:47,  4.96s/it] - Epoch: 4 | Train_loss: 1.0720, Train_acc: 0.429% | Test_loss: 1.0243, Test_acc: 0.495%\n",
            " 10% 5/50 [00:24<03:30,  4.67s/it] - Epoch: 5 | Train_loss: 1.0594, Train_acc: 0.460% | Test_loss: 0.9737, Test_acc: 0.533%\n",
            " 12% 6/50 [00:29<03:32,  4.83s/it] - Epoch: 6 | Train_loss: 0.9962, Train_acc: 0.485% | Test_loss: 0.9385, Test_acc: 0.509%\n",
            " 14% 7/50 [00:34<03:22,  4.72s/it] - Epoch: 7 | Train_loss: 1.0276, Train_acc: 0.433% | Test_loss: 0.9339, Test_acc: 0.601%\n",
            " 16% 8/50 [00:38<03:13,  4.60s/it] - Epoch: 8 | Train_loss: 0.9588, Train_acc: 0.537% | Test_loss: 0.9302, Test_acc: 0.604%\n",
            " 18% 9/50 [00:43<03:18,  4.84s/it] - Epoch: 9 | Train_loss: 0.9919, Train_acc: 0.440% | Test_loss: 0.9166, Test_acc: 0.594%\n",
            " 20% 10/50 [00:48<03:06,  4.66s/it] - Epoch: 10 | Train_loss: 1.0137, Train_acc: 0.508% | Test_loss: 0.9249, Test_acc: 0.594%\n",
            " 22% 11/50 [00:52<02:56,  4.53s/it] - Epoch: 11 | Train_loss: 0.9807, Train_acc: 0.506% | Test_loss: 0.9261, Test_acc: 0.528%\n",
            " 24% 12/50 [00:57<03:02,  4.81s/it] - Epoch: 12 | Train_loss: 0.9546, Train_acc: 0.544% | Test_loss: 0.9179, Test_acc: 0.582%\n",
            " 26% 13/50 [01:02<02:52,  4.67s/it] - Epoch: 13 | Train_loss: 0.9265, Train_acc: 0.550% | Test_loss: 0.9360, Test_acc: 0.546%\n",
            " 28% 14/50 [01:06<02:42,  4.53s/it] - Epoch: 14 | Train_loss: 0.9733, Train_acc: 0.506% | Test_loss: 0.9149, Test_acc: 0.525%\n",
            " 30% 15/50 [01:11<02:48,  4.81s/it] - Epoch: 15 | Train_loss: 0.9660, Train_acc: 0.523% | Test_loss: 0.9165, Test_acc: 0.595%\n",
            " 32% 16/50 [01:16<02:37,  4.64s/it] - Epoch: 16 | Train_loss: 0.9769, Train_acc: 0.533% | Test_loss: 0.9152, Test_acc: 0.588%\n",
            " 34% 17/50 [01:20<02:34,  4.69s/it] - Epoch: 17 | Train_loss: 0.9552, Train_acc: 0.525% | Test_loss: 0.9114, Test_acc: 0.557%\n",
            " 36% 18/50 [01:25<02:32,  4.77s/it] - Epoch: 18 | Train_loss: 0.9333, Train_acc: 0.479% | Test_loss: 0.9081, Test_acc: 0.610%\n",
            " 38% 19/50 [01:30<02:22,  4.61s/it] - Epoch: 19 | Train_loss: 0.9727, Train_acc: 0.533% | Test_loss: 0.9185, Test_acc: 0.601%\n",
            " 40% 20/50 [01:35<02:26,  4.88s/it] - Epoch: 20 | Train_loss: 0.9813, Train_acc: 0.500% | Test_loss: 0.9089, Test_acc: 0.620%\n",
            " 42% 21/50 [01:39<02:16,  4.70s/it] - Epoch: 21 | Train_loss: 0.9145, Train_acc: 0.588% | Test_loss: 0.9107, Test_acc: 0.607%\n",
            " 44% 22/50 [01:44<02:07,  4.56s/it] - Epoch: 22 | Train_loss: 0.9143, Train_acc: 0.548% | Test_loss: 0.9078, Test_acc: 0.595%\n",
            " 46% 23/50 [01:49<02:09,  4.78s/it] - Epoch: 23 | Train_loss: 0.8735, Train_acc: 0.575% | Test_loss: 0.9133, Test_acc: 0.588%\n",
            " 48% 24/50 [01:54<02:02,  4.72s/it] - Epoch: 24 | Train_loss: 0.9215, Train_acc: 0.552% | Test_loss: 0.9036, Test_acc: 0.540%\n",
            " 50% 25/50 [01:58<01:54,  4.57s/it] - Epoch: 25 | Train_loss: 0.9683, Train_acc: 0.508% | Test_loss: 0.8982, Test_acc: 0.616%\n",
            " 52% 26/50 [02:03<01:55,  4.82s/it] - Epoch: 26 | Train_loss: 0.9189, Train_acc: 0.546% | Test_loss: 0.9004, Test_acc: 0.600%\n",
            " 54% 27/50 [02:07<01:47,  4.67s/it] - Epoch: 27 | Train_loss: 0.9445, Train_acc: 0.517% | Test_loss: 0.8896, Test_acc: 0.567%\n",
            " 56% 28/50 [02:12<01:43,  4.71s/it] - Epoch: 28 | Train_loss: 0.9162, Train_acc: 0.554% | Test_loss: 0.9022, Test_acc: 0.553%\n",
            " 58% 29/50 [02:17<01:39,  4.74s/it] - Epoch: 29 | Train_loss: 0.9127, Train_acc: 0.567% | Test_loss: 0.8804, Test_acc: 0.613%\n",
            " 60% 30/50 [02:21<01:31,  4.57s/it] - Epoch: 30 | Train_loss: 0.9166, Train_acc: 0.573% | Test_loss: 0.9080, Test_acc: 0.559%\n",
            " 62% 31/50 [02:26<01:29,  4.73s/it] - Epoch: 31 | Train_loss: 0.8923, Train_acc: 0.613% | Test_loss: 0.9021, Test_acc: 0.540%\n",
            " 64% 32/50 [02:31<01:22,  4.60s/it] - Epoch: 32 | Train_loss: 0.9524, Train_acc: 0.567% | Test_loss: 0.8838, Test_acc: 0.588%\n",
            " 66% 33/50 [02:35<01:16,  4.51s/it] - Epoch: 33 | Train_loss: 0.8899, Train_acc: 0.588% | Test_loss: 0.8863, Test_acc: 0.558%\n",
            " 68% 34/50 [02:40<01:16,  4.76s/it] - Epoch: 34 | Train_loss: 0.9444, Train_acc: 0.529% | Test_loss: 0.8773, Test_acc: 0.573%\n",
            " 70% 35/50 [02:44<01:08,  4.58s/it] - Epoch: 35 | Train_loss: 0.9093, Train_acc: 0.573% | Test_loss: 0.9062, Test_acc: 0.537%\n",
            " 72% 36/50 [02:49<01:01,  4.42s/it] - Epoch: 36 | Train_loss: 0.9567, Train_acc: 0.548% | Test_loss: 0.8795, Test_acc: 0.579%\n",
            " 74% 37/50 [02:54<01:00,  4.67s/it] - Epoch: 37 | Train_loss: 0.8796, Train_acc: 0.606% | Test_loss: 0.8806, Test_acc: 0.631%\n",
            " 76% 38/50 [02:58<00:54,  4.52s/it] - Epoch: 38 | Train_loss: 0.8912, Train_acc: 0.617% | Test_loss: 0.8742, Test_acc: 0.601%\n",
            " 78% 39/50 [03:02<00:48,  4.41s/it] - Epoch: 39 | Train_loss: 0.9399, Train_acc: 0.554% | Test_loss: 0.8557, Test_acc: 0.622%\n",
            " 80% 40/50 [03:07<00:47,  4.70s/it] - Epoch: 40 | Train_loss: 0.9646, Train_acc: 0.546% | Test_loss: 0.8624, Test_acc: 0.615%\n",
            " 82% 41/50 [03:12<00:40,  4.55s/it] - Epoch: 41 | Train_loss: 0.9042, Train_acc: 0.550% | Test_loss: 0.8619, Test_acc: 0.628%\n",
            " 84% 42/50 [03:16<00:36,  4.55s/it] - Epoch: 42 | Train_loss: 0.9140, Train_acc: 0.573% | Test_loss: 0.8588, Test_acc: 0.628%\n",
            " 86% 43/50 [03:21<00:33,  4.76s/it] - Epoch: 43 | Train_loss: 0.8974, Train_acc: 0.502% | Test_loss: 0.8536, Test_acc: 0.598%\n",
            " 88% 44/50 [03:26<00:27,  4.61s/it] - Epoch: 44 | Train_loss: 0.8733, Train_acc: 0.560% | Test_loss: 0.8569, Test_acc: 0.604%\n",
            " 90% 45/50 [03:31<00:23,  4.77s/it] - Epoch: 45 | Train_loss: 0.8482, Train_acc: 0.604% | Test_loss: 0.8412, Test_acc: 0.606%\n",
            " 92% 46/50 [03:35<00:18,  4.68s/it] - Epoch: 46 | Train_loss: 0.9048, Train_acc: 0.583% | Test_loss: 0.8984, Test_acc: 0.558%\n",
            " 94% 47/50 [03:40<00:13,  4.56s/it] - Epoch: 47 | Train_loss: 0.9372, Train_acc: 0.544% | Test_loss: 0.8833, Test_acc: 0.590%\n",
            " 96% 48/50 [03:45<00:09,  4.79s/it] - Epoch: 48 | Train_loss: 0.8965, Train_acc: 0.575% | Test_loss: 0.8503, Test_acc: 0.588%\n",
            " 98% 49/50 [03:49<00:04,  4.62s/it] - Epoch: 49 | Train_loss: 0.8378, Train_acc: 0.631% | Test_loss: 0.8529, Test_acc: 0.616%\n",
            "100% 50/50 [03:53<00:00,  4.68s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3\n",
        "Create a Python script to predict on a target image given a file path with a saved model.\n",
        "\n",
        "* For example, you should be able to run the command `python predict.py some_image.jpeg` and have a trained PyTorch model predict on the image and return its prediction.\n",
        "* To see example prediction code, check out the prediction on a custom image section in notebook 04.\n",
        "* You may also have to write code to load in a trained model."
      ],
      "metadata": {
        "id": "KzdjA65mAuuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/predict.py\n",
        "import argparse\n",
        "import logging\n",
        "import model_builder\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Creating a parser\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# Get an image path\n",
        "parser.add_argument(\n",
        "    \"--image\",\n",
        "    help=\"target image filepath to predict on\")\n",
        "\n",
        "# Get a model path\n",
        "parser.add_argument(\n",
        "    \"--model_path\",\n",
        "    default=\"models/tinyvgg_model.pth\",\n",
        "    type=str,\n",
        "    help=\"target model to use for prediction\")\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Setup class names\n",
        "class_name_list = [\"pizza\", \"steak\", \"sushi\"]\n",
        "\n",
        "# Setup device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Get the image path\n",
        "IMAGE = args.image\n",
        "logging.info(f\"Predicting on {IMAGE}\")\n",
        "\n",
        "# Load in the model\n",
        "model = model_builder.TinyVGG(\n",
        "    in_channels=3,\n",
        "    hidden_units=20,\n",
        "    out_features=len(class_name_list),\n",
        "    img_shape=(64, 64))\n",
        "\n",
        "model.load_state_dict(torch.load(args.model_path))\n",
        "\n",
        "# Data preparation\n",
        "image = torchvision.io.read_image(str(IMAGE)).type(torch.float32)\n",
        "image = image / 255.0\n",
        "\n",
        "transform = torchvision.transforms.Resize(size=(64, 64))\n",
        "image = transform(image)\n",
        "\n",
        "# Predict on image\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "    # Send image to target device\n",
        "    image = image.to(device)\n",
        "\n",
        "    # Get pred logits\n",
        "    pred_logits = model(image.unsqueeze(dim=0))\n",
        "    pred_prob = torch.softmax(pred_logits, dim=1)\n",
        "    pred_label = torch.argmax(pred_prob, dim=1)\n",
        "\n",
        "print(f\"Pred class: {class_name_list[pred_label]}, Pred prob: {pred_prob.max():.3f}\")  # noqa: E501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnnU62LYEMLO",
        "outputId": "272adce9-a760-4635-f214-33ccc577f75c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python going_modular/predict.py --image data/pizza_steak_sushi/test/pizza/1555015.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP7VyHm9HbVQ",
        "outputId": "0162c182-74cc-412d-9b40-77b8e372e22f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred class: pizza, Pred prob: 0.462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QBZLTp4lHozG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}